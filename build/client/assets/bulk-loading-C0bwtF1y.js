import{j as e}from"./chunk-OIYGIGL5-BFuAKb0n.js";let s="## Overview\n\nHBase includes several methods of loading data into tables. The most straightforward method is to either use the `TableOutputFormat` class from a MapReduce job, or use the normal client APIs; however, these are not always the most efficient methods.\n\nThe bulk load feature uses a MapReduce job to output table data in HBase's internal data format, and then directly load the generated StoreFiles into a running cluster. Using bulk load will use less CPU and network resources than loading via the HBase API.\n\n## Bulk Load Architecture\n\nThe HBase bulk load process consists of two main steps.\n\n### Preparing data via a MapReduce job\n\nThe first step of a bulk load is to generate HBase data files (StoreFiles) from a MapReduce job using `HFileOutputFormat2`. This output format writes out data in HBase's internal storage format so that they can be later loaded efficiently into the cluster.\n\nIn order to function efficiently, `HFileOutputFormat2` must be configured such that each output HFile fits within a single region. In order to do this, jobs whose output will be bulk loaded into HBase use Hadoop's `TotalOrderPartitioner` class to partition the map output into disjoint ranges of the key space, corresponding to the key ranges of the regions in the table.\n\n`HFileOutputFormat2` includes a convenience function, `configureIncrementalLoad()`, which automatically sets up a `TotalOrderPartitioner` based on the current region boundaries of a table.\n\n### Completing the data load\n\nAfter a data import has been prepared, either by using the `importtsv` tool with the “importtsv.bulk.output” option or by some other MapReduce job using the `HFileOutputFormat`, the `completebulkload` tool is used to import the data into the running cluster. This command line tool iterates through the prepared data files, and for each one determines the region the file belongs to. It then contacts the appropriate RegionServer which adopts the HFile, moving it into its storage directory and making the data available to clients.\n\nIf the region boundaries have changed during the course of bulk load preparation, or between the preparation and completion steps, the `completebulkload` utility will automatically split the data files into pieces corresponding to the new boundaries. This process is not optimally efficient, so users should take care to minimize the delay between preparing a bulk load and importing it into the cluster, especially if other clients are simultaneously loading data through other means.\n\n```bash\n$ hadoop jar hbase-mapreduce-VERSION.jar completebulkload [-c /path/to/hbase/config/hbase-site.xml] /user/todd/myoutput mytable\n```\n\nThe `-c config-file` option can be used to specify a file containing the appropriate hbase parameters (e.g., hbase-site.xml) if not supplied already on the CLASSPATH (In addition, the CLASSPATH must contain the directory that has the zookeeper configuration file if zookeeper is NOT managed by HBase).\n\n## See Also\n\nFor more information about the referenced utilities, see [ImportTsv](/docs/operational-management/tools#importtsv) and [CompleteBulkLoad](/docs/operational-management/tools#completebulkload).\n\nSee [How-to: Use HBase Bulk Loading, and Why](http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/) for an old blog post on loading.\n\n## Advanced Usage\n\nAlthough the `importtsv` tool is useful in many cases, advanced users may want to generate data programmatically, or import data from other formats. To get started doing so, dig into `ImportTsv.java` and check the JavaDoc for HFileOutputFormat.\n\nThe import step of the bulk load can also be done programmatically. See the `LoadIncrementalHFiles` class for more information.\n\n### 'Adopting' Stray Data\n\nShould an HBase cluster lose account of regions or files during an outage or error, you can use the `completebulkload` tool to add back the dropped data. HBase operator tooling such as [HBCK2](https://github.com/apache/hbase-operator-tools/tree/master/hbase-hbck2) or the reporting added to the Master's UI under the `HBCK Report` (Since HBase 2.0.6/2.1.6/2.2.1) can identify such 'orphan' directories.\n\nBefore you begin the 'adoption', ensure the `hbase:meta` table is in a healthy state. Run the `CatalogJanitor` by executing the `catalogjanitor_run` command on the HBase shell. When finished, check the `HBCK Report` page on the Master UI. Work on fixing any inconsistencies, holes, or overlaps found before proceeding. The `hbase:meta` table is the authority on where all data is to be found and must be consistent for the `completebulkload` tool to work properly.\n\nThe `completebulkload` tool takes a directory and a `tablename`. The directory has subdirectories named for column families of the targeted `tablename`. In these subdirectories are `hfiles` to load. Given this structure, you can pass errant region directories (and the table name to which the region directory belongs) and the tool will bring the data files back into the fold by moving them under the approprate serving directory. If stray files, then you will need to mock up this structure before invoking the `completebulkload` tool; you may have to look at the file content using the [HFile Tool](/docs/operational-management/tools#operational-management-tools-hfile-tool) to see what the column family to use is. When the tool completes its run, you will notice that the source errant directory has had its storefiles moved/removed. It is now desiccated since its data has been drained, and the pointed-to directory can be safely removed. It may still have `.regioninfo` files and other subdirectories but they are of no relevance now (There may be content still under the *recovered\\_edits* directory; a TODO is tooling to replay the content of *recovered\\_edits* if needed; see [Add RecoveredEditsPlayer](https://issues.apache.org/jira/browse/HBASE-22976)). If you pass `completebulkload` a directory without store files, it will run and note the directory is storefile-free. Just remove such 'empty' directories.\n\nFor example, presuming a directory at the top level in HDFS named `eb3352fb5c9c9a05feeb2caba101e1cc` has data we need to re-add to the HBase `TestTable`:\n\n```bash\n$ ${HBASE_HOME}/bin/hbase --config ~/hbase-conf completebulkload hdfs://server.example.org:9000/eb3352fb5c9c9a05feeb2caba101e1cc TestTable\n```\n\nAfter it successfully completes, any files that were in `eb3352fb5c9c9a05feeb2caba101e1cc` have been moved under hbase and the `eb3352fb5c9c9a05feeb2caba101e1cc` directory can be deleted (Check content before and after by running `ls -r` on the HDFS directory).\n\n## Bulk Loading Replication\n\nHBASE-13153 adds replication support for bulk loaded HFiles, available since HBase 1.3/2.0. This feature is enabled by setting `hbase.replication.bulkload.enabled` to `true` (default is `false`). You also need to copy the source cluster configuration files to the destination cluster.\n\nAdditional configurations are required too:\n\n1. `hbase.replication.source.fs.conf.provider`\\\n   This defines the class which loads the source cluster file system client configuration in the destination cluster. This should be configured for all the RS in the destination cluster. Default is `org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider`.\n2. `hbase.replication.conf.dir`\\\n   This represents the base directory where the file system client configurations of the source cluster are copied to the destination cluster. This should be configured for all the RS in the destination cluster. Default is `$HBASE_CONF_DIR`.\n3. `hbase.replication.cluster.id`\\\n   This configuration is required in the cluster where replication for bulk loaded data is enabled. A source cluster is uniquely identified by the destination cluster using this id. This should be configured for all the RS in the source cluster configuration file for all the RS.\n\nFor example: If source cluster FS client configurations are copied to the destination cluster under directory `/home/user/dc1/`, then `hbase.replication.cluster.id` should be configured as `dc1` and `hbase.replication.conf.dir` as `/home/user`.\n\n<Callout type=\"info\">\n  `DefaultSourceFSConfigurationProvider` supports only `xml` type files. It loads source cluster FS\n  client configuration only once, so if source cluster FS client configuration files are updated,\n  every peer(s) cluster RS must be restarted to reload the configuration.\n</Callout>\n",l={title:"Bulk Loading",description:"Efficient methods for loading large datasets into HBase using MapReduce to generate HFiles and directly load them into the cluster."},d=[{href:"/docs/operational-management/tools#importtsv"},{href:"/docs/operational-management/tools#completebulkload"},{href:"http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/"},{href:"https://github.com/apache/hbase-operator-tools/tree/master/hbase-hbck2"},{href:"/docs/operational-management/tools#operational-management-tools-hfile-tool"},{href:"https://issues.apache.org/jira/browse/HBASE-22976"}],c={contents:[{heading:"bulk-loading-overview",content:"HBase includes several methods of loading data into tables. The most straightforward method is to either use the TableOutputFormat class from a MapReduce job, or use the normal client APIs; however, these are not always the most efficient methods."},{heading:"bulk-loading-overview",content:"The bulk load feature uses a MapReduce job to output table data in HBase's internal data format, and then directly load the generated StoreFiles into a running cluster. Using bulk load will use less CPU and network resources than loading via the HBase API."},{heading:"bulk-load-architecture",content:"The HBase bulk load process consists of two main steps."},{heading:"preparing-data-via-a-mapreduce-job",content:"The first step of a bulk load is to generate HBase data files (StoreFiles) from a MapReduce job using HFileOutputFormat2. This output format writes out data in HBase's internal storage format so that they can be later loaded efficiently into the cluster."},{heading:"preparing-data-via-a-mapreduce-job",content:"In order to function efficiently, HFileOutputFormat2 must be configured such that each output HFile fits within a single region. In order to do this, jobs whose output will be bulk loaded into HBase use Hadoop's TotalOrderPartitioner class to partition the map output into disjoint ranges of the key space, corresponding to the key ranges of the regions in the table."},{heading:"preparing-data-via-a-mapreduce-job",content:"HFileOutputFormat2 includes a convenience function, configureIncrementalLoad(), which automatically sets up a TotalOrderPartitioner based on the current region boundaries of a table."},{heading:"completing-the-data-load",content:"After a data import has been prepared, either by using the importtsv tool with the “importtsv.bulk.output” option or by some other MapReduce job using the HFileOutputFormat, the completebulkload tool is used to import the data into the running cluster. This command line tool iterates through the prepared data files, and for each one determines the region the file belongs to. It then contacts the appropriate RegionServer which adopts the HFile, moving it into its storage directory and making the data available to clients."},{heading:"completing-the-data-load",content:"If the region boundaries have changed during the course of bulk load preparation, or between the preparation and completion steps, the completebulkload utility will automatically split the data files into pieces corresponding to the new boundaries. This process is not optimally efficient, so users should take care to minimize the delay between preparing a bulk load and importing it into the cluster, especially if other clients are simultaneously loading data through other means."},{heading:"completing-the-data-load",content:"The -c config-file option can be used to specify a file containing the appropriate hbase parameters (e.g., hbase-site.xml) if not supplied already on the CLASSPATH (In addition, the CLASSPATH must contain the directory that has the zookeeper configuration file if zookeeper is NOT managed by HBase)."},{heading:"bulk-loading-see-also",content:"For more information about the referenced utilities, see ImportTsv and CompleteBulkLoad."},{heading:"bulk-loading-see-also",content:"See How-to: Use HBase Bulk Loading, and Why for an old blog post on loading."},{heading:"advanced-usage",content:"Although the importtsv tool is useful in many cases, advanced users may want to generate data programmatically, or import data from other formats. To get started doing so, dig into ImportTsv.java and check the JavaDoc for HFileOutputFormat."},{heading:"advanced-usage",content:"The import step of the bulk load can also be done programmatically. See the LoadIncrementalHFiles class for more information."},{heading:"adopting-stray-data",content:"Should an HBase cluster lose account of regions or files during an outage or error, you can use the completebulkload tool to add back the dropped data. HBase operator tooling such as HBCK2 or the reporting added to the Master's UI under the HBCK Report (Since HBase 2.0.6/2.1.6/2.2.1) can identify such 'orphan' directories."},{heading:"adopting-stray-data",content:"Before you begin the 'adoption', ensure the hbase:meta table is in a healthy state. Run the CatalogJanitor by executing the catalogjanitor_run command on the HBase shell. When finished, check the HBCK Report page on the Master UI. Work on fixing any inconsistencies, holes, or overlaps found before proceeding. The hbase:meta table is the authority on where all data is to be found and must be consistent for the completebulkload tool to work properly."},{heading:"adopting-stray-data",content:"The completebulkload tool takes a directory and a tablename. The directory has subdirectories named for column families of the targeted tablename. In these subdirectories are hfiles to load. Given this structure, you can pass errant region directories (and the table name to which the region directory belongs) and the tool will bring the data files back into the fold by moving them under the approprate serving directory. If stray files, then you will need to mock up this structure before invoking the completebulkload tool; you may have to look at the file content using the HFile Tool to see what the column family to use is. When the tool completes its run, you will notice that the source errant directory has had its storefiles moved/removed. It is now desiccated since its data has been drained, and the pointed-to directory can be safely removed. It may still have .regioninfo files and other subdirectories but they are of no relevance now (There may be content still under the recovered_edits directory; a TODO is tooling to replay the content of recovered_edits if needed; see Add RecoveredEditsPlayer). If you pass completebulkload a directory without store files, it will run and note the directory is storefile-free. Just remove such 'empty' directories."},{heading:"adopting-stray-data",content:"For example, presuming a directory at the top level in HDFS named eb3352fb5c9c9a05feeb2caba101e1cc has data we need to re-add to the HBase TestTable:"},{heading:"adopting-stray-data",content:"After it successfully completes, any files that were in eb3352fb5c9c9a05feeb2caba101e1cc have been moved under hbase and the eb3352fb5c9c9a05feeb2caba101e1cc directory can be deleted (Check content before and after by running ls -r on the HDFS directory)."},{heading:"bulk-loading-replication",content:"HBASE-13153 adds replication support for bulk loaded HFiles, available since HBase 1.3/2.0. This feature is enabled by setting hbase.replication.bulkload.enabled to true (default is false). You also need to copy the source cluster configuration files to the destination cluster."},{heading:"bulk-loading-replication",content:"Additional configurations are required too:"},{heading:"bulk-loading-replication",content:"hbase.replication.source.fs.conf.providerThis defines the class which loads the source cluster file system client configuration in the destination cluster. This should be configured for all the RS in the destination cluster. Default is org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider."},{heading:"bulk-loading-replication",content:"hbase.replication.conf.dirThis represents the base directory where the file system client configurations of the source cluster are copied to the destination cluster. This should be configured for all the RS in the destination cluster. Default is $HBASE_CONF_DIR."},{heading:"bulk-loading-replication",content:"hbase.replication.cluster.idThis configuration is required in the cluster where replication for bulk loaded data is enabled. A source cluster is uniquely identified by the destination cluster using this id. This should be configured for all the RS in the source cluster configuration file for all the RS."},{heading:"bulk-loading-replication",content:"For example: If source cluster FS client configurations are copied to the destination cluster under directory /home/user/dc1/, then hbase.replication.cluster.id should be configured as dc1 and hbase.replication.conf.dir as /home/user."},{heading:"bulk-loading-replication",content:"type: info"},{heading:"bulk-loading-replication",content:`DefaultSourceFSConfigurationProvider supports only xml type files. It loads source cluster FS
client configuration only once, so if source cluster FS client configuration files are updated,
every peer(s) cluster RS must be restarted to reload the configuration.`}],headings:[{id:"bulk-loading-overview",content:"Overview"},{id:"bulk-load-architecture",content:"Bulk Load Architecture"},{id:"preparing-data-via-a-mapreduce-job",content:"Preparing data via a MapReduce job"},{id:"completing-the-data-load",content:"Completing the data load"},{id:"bulk-loading-see-also",content:"See Also"},{id:"advanced-usage",content:"Advanced Usage"},{id:"adopting-stray-data",content:"'Adopting' Stray Data"},{id:"bulk-loading-replication",content:"Bulk Loading Replication"}]};const h=[{depth:2,url:"#bulk-loading-overview",title:e.jsx(e.Fragment,{children:"Overview"})},{depth:2,url:"#bulk-load-architecture",title:e.jsx(e.Fragment,{children:"Bulk Load Architecture"})},{depth:3,url:"#preparing-data-via-a-mapreduce-job",title:e.jsx(e.Fragment,{children:"Preparing data via a MapReduce job"})},{depth:3,url:"#completing-the-data-load",title:e.jsx(e.Fragment,{children:"Completing the data load"})},{depth:2,url:"#bulk-loading-see-also",title:e.jsx(e.Fragment,{children:"See Also"})},{depth:2,url:"#advanced-usage",title:e.jsx(e.Fragment,{children:"Advanced Usage"})},{depth:3,url:"#adopting-stray-data",title:e.jsx(e.Fragment,{children:"'Adopting' Stray Data"})},{depth:2,url:"#bulk-loading-replication",title:e.jsx(e.Fragment,{children:"Bulk Loading Replication"})}];function i(o){const t={a:"a",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",...o.components},{Callout:a}=t;return a||n("Callout"),e.jsxs(e.Fragment,{children:[e.jsx(t.h2,{id:"bulk-loading-overview",children:"Overview"}),`
`,e.jsxs(t.p,{children:["HBase includes several methods of loading data into tables. The most straightforward method is to either use the ",e.jsx(t.code,{children:"TableOutputFormat"})," class from a MapReduce job, or use the normal client APIs; however, these are not always the most efficient methods."]}),`
`,e.jsx(t.p,{children:"The bulk load feature uses a MapReduce job to output table data in HBase's internal data format, and then directly load the generated StoreFiles into a running cluster. Using bulk load will use less CPU and network resources than loading via the HBase API."}),`
`,e.jsx(t.h2,{id:"bulk-load-architecture",children:"Bulk Load Architecture"}),`
`,e.jsx(t.p,{children:"The HBase bulk load process consists of two main steps."}),`
`,e.jsx(t.h3,{id:"preparing-data-via-a-mapreduce-job",children:"Preparing data via a MapReduce job"}),`
`,e.jsxs(t.p,{children:["The first step of a bulk load is to generate HBase data files (StoreFiles) from a MapReduce job using ",e.jsx(t.code,{children:"HFileOutputFormat2"}),". This output format writes out data in HBase's internal storage format so that they can be later loaded efficiently into the cluster."]}),`
`,e.jsxs(t.p,{children:["In order to function efficiently, ",e.jsx(t.code,{children:"HFileOutputFormat2"})," must be configured such that each output HFile fits within a single region. In order to do this, jobs whose output will be bulk loaded into HBase use Hadoop's ",e.jsx(t.code,{children:"TotalOrderPartitioner"})," class to partition the map output into disjoint ranges of the key space, corresponding to the key ranges of the regions in the table."]}),`
`,e.jsxs(t.p,{children:[e.jsx(t.code,{children:"HFileOutputFormat2"})," includes a convenience function, ",e.jsx(t.code,{children:"configureIncrementalLoad()"}),", which automatically sets up a ",e.jsx(t.code,{children:"TotalOrderPartitioner"})," based on the current region boundaries of a table."]}),`
`,e.jsx(t.h3,{id:"completing-the-data-load",children:"Completing the data load"}),`
`,e.jsxs(t.p,{children:["After a data import has been prepared, either by using the ",e.jsx(t.code,{children:"importtsv"})," tool with the “importtsv.bulk.output” option or by some other MapReduce job using the ",e.jsx(t.code,{children:"HFileOutputFormat"}),", the ",e.jsx(t.code,{children:"completebulkload"})," tool is used to import the data into the running cluster. This command line tool iterates through the prepared data files, and for each one determines the region the file belongs to. It then contacts the appropriate RegionServer which adopts the HFile, moving it into its storage directory and making the data available to clients."]}),`
`,e.jsxs(t.p,{children:["If the region boundaries have changed during the course of bulk load preparation, or between the preparation and completion steps, the ",e.jsx(t.code,{children:"completebulkload"})," utility will automatically split the data files into pieces corresponding to the new boundaries. This process is not optimally efficient, so users should take care to minimize the delay between preparing a bulk load and importing it into the cluster, especially if other clients are simultaneously loading data through other means."]}),`
`,e.jsx(e.Fragment,{children:e.jsx(t.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:e.jsx(t.code,{children:e.jsxs(t.span,{className:"line",children:[e.jsx(t.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"$"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" hadoop"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" jar"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" hbase-mapreduce-VERSION.jar"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" completebulkload"}),e.jsx(t.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" [-c "}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:"/path/to/hbase/config/hbase-site.xml]"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" /user/todd/myoutput"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" mytable"})]})})})}),`
`,e.jsxs(t.p,{children:["The ",e.jsx(t.code,{children:"-c config-file"})," option can be used to specify a file containing the appropriate hbase parameters (e.g., hbase-site.xml) if not supplied already on the CLASSPATH (In addition, the CLASSPATH must contain the directory that has the zookeeper configuration file if zookeeper is NOT managed by HBase)."]}),`
`,e.jsx(t.h2,{id:"bulk-loading-see-also",children:"See Also"}),`
`,e.jsxs(t.p,{children:["For more information about the referenced utilities, see ",e.jsx(t.a,{href:"/docs/operational-management/tools#importtsv",children:"ImportTsv"})," and ",e.jsx(t.a,{href:"/docs/operational-management/tools#completebulkload",children:"CompleteBulkLoad"}),"."]}),`
`,e.jsxs(t.p,{children:["See ",e.jsx(t.a,{href:"http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/",children:"How-to: Use HBase Bulk Loading, and Why"})," for an old blog post on loading."]}),`
`,e.jsx(t.h2,{id:"advanced-usage",children:"Advanced Usage"}),`
`,e.jsxs(t.p,{children:["Although the ",e.jsx(t.code,{children:"importtsv"})," tool is useful in many cases, advanced users may want to generate data programmatically, or import data from other formats. To get started doing so, dig into ",e.jsx(t.code,{children:"ImportTsv.java"})," and check the JavaDoc for HFileOutputFormat."]}),`
`,e.jsxs(t.p,{children:["The import step of the bulk load can also be done programmatically. See the ",e.jsx(t.code,{children:"LoadIncrementalHFiles"})," class for more information."]}),`
`,e.jsx(t.h3,{id:"adopting-stray-data",children:"'Adopting' Stray Data"}),`
`,e.jsxs(t.p,{children:["Should an HBase cluster lose account of regions or files during an outage or error, you can use the ",e.jsx(t.code,{children:"completebulkload"})," tool to add back the dropped data. HBase operator tooling such as ",e.jsx(t.a,{href:"https://github.com/apache/hbase-operator-tools/tree/master/hbase-hbck2",children:"HBCK2"})," or the reporting added to the Master's UI under the ",e.jsx(t.code,{children:"HBCK Report"})," (Since HBase 2.0.6/2.1.6/2.2.1) can identify such 'orphan' directories."]}),`
`,e.jsxs(t.p,{children:["Before you begin the 'adoption', ensure the ",e.jsx(t.code,{children:"hbase:meta"})," table is in a healthy state. Run the ",e.jsx(t.code,{children:"CatalogJanitor"})," by executing the ",e.jsx(t.code,{children:"catalogjanitor_run"})," command on the HBase shell. When finished, check the ",e.jsx(t.code,{children:"HBCK Report"})," page on the Master UI. Work on fixing any inconsistencies, holes, or overlaps found before proceeding. The ",e.jsx(t.code,{children:"hbase:meta"})," table is the authority on where all data is to be found and must be consistent for the ",e.jsx(t.code,{children:"completebulkload"})," tool to work properly."]}),`
`,e.jsxs(t.p,{children:["The ",e.jsx(t.code,{children:"completebulkload"})," tool takes a directory and a ",e.jsx(t.code,{children:"tablename"}),". The directory has subdirectories named for column families of the targeted ",e.jsx(t.code,{children:"tablename"}),". In these subdirectories are ",e.jsx(t.code,{children:"hfiles"})," to load. Given this structure, you can pass errant region directories (and the table name to which the region directory belongs) and the tool will bring the data files back into the fold by moving them under the approprate serving directory. If stray files, then you will need to mock up this structure before invoking the ",e.jsx(t.code,{children:"completebulkload"})," tool; you may have to look at the file content using the ",e.jsx(t.a,{href:"/docs/operational-management/tools#operational-management-tools-hfile-tool",children:"HFile Tool"})," to see what the column family to use is. When the tool completes its run, you will notice that the source errant directory has had its storefiles moved/removed. It is now desiccated since its data has been drained, and the pointed-to directory can be safely removed. It may still have ",e.jsx(t.code,{children:".regioninfo"})," files and other subdirectories but they are of no relevance now (There may be content still under the ",e.jsx(t.em,{children:"recovered_edits"})," directory; a TODO is tooling to replay the content of ",e.jsx(t.em,{children:"recovered_edits"})," if needed; see ",e.jsx(t.a,{href:"https://issues.apache.org/jira/browse/HBASE-22976",children:"Add RecoveredEditsPlayer"}),"). If you pass ",e.jsx(t.code,{children:"completebulkload"})," a directory without store files, it will run and note the directory is storefile-free. Just remove such 'empty' directories."]}),`
`,e.jsxs(t.p,{children:["For example, presuming a directory at the top level in HDFS named ",e.jsx(t.code,{children:"eb3352fb5c9c9a05feeb2caba101e1cc"})," has data we need to re-add to the HBase ",e.jsx(t.code,{children:"TestTable"}),":"]}),`
`,e.jsx(e.Fragment,{children:e.jsx(t.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:e.jsx(t.code,{children:e.jsxs(t.span,{className:"line",children:[e.jsx(t.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"$"}),e.jsx(t.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" ${HBASE_HOME}"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:"/bin/hbase"}),e.jsx(t.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:" --config"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" ~/hbase-conf"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" completebulkload"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" hdfs://server.example.org:9000/eb3352fb5c9c9a05feeb2caba101e1cc"}),e.jsx(t.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" TestTable"})]})})})}),`
`,e.jsxs(t.p,{children:["After it successfully completes, any files that were in ",e.jsx(t.code,{children:"eb3352fb5c9c9a05feeb2caba101e1cc"})," have been moved under hbase and the ",e.jsx(t.code,{children:"eb3352fb5c9c9a05feeb2caba101e1cc"})," directory can be deleted (Check content before and after by running ",e.jsx(t.code,{children:"ls -r"})," on the HDFS directory)."]}),`
`,e.jsx(t.h2,{id:"bulk-loading-replication",children:"Bulk Loading Replication"}),`
`,e.jsxs(t.p,{children:["HBASE-13153 adds replication support for bulk loaded HFiles, available since HBase 1.3/2.0. This feature is enabled by setting ",e.jsx(t.code,{children:"hbase.replication.bulkload.enabled"})," to ",e.jsx(t.code,{children:"true"})," (default is ",e.jsx(t.code,{children:"false"}),"). You also need to copy the source cluster configuration files to the destination cluster."]}),`
`,e.jsx(t.p,{children:"Additional configurations are required too:"}),`
`,e.jsxs(t.ol,{children:[`
`,e.jsxs(t.li,{children:[e.jsx(t.code,{children:"hbase.replication.source.fs.conf.provider"}),e.jsx(t.br,{}),`
`,"This defines the class which loads the source cluster file system client configuration in the destination cluster. This should be configured for all the RS in the destination cluster. Default is ",e.jsx(t.code,{children:"org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider"}),"."]}),`
`,e.jsxs(t.li,{children:[e.jsx(t.code,{children:"hbase.replication.conf.dir"}),e.jsx(t.br,{}),`
`,"This represents the base directory where the file system client configurations of the source cluster are copied to the destination cluster. This should be configured for all the RS in the destination cluster. Default is ",e.jsx(t.code,{children:"$HBASE_CONF_DIR"}),"."]}),`
`,e.jsxs(t.li,{children:[e.jsx(t.code,{children:"hbase.replication.cluster.id"}),e.jsx(t.br,{}),`
`,"This configuration is required in the cluster where replication for bulk loaded data is enabled. A source cluster is uniquely identified by the destination cluster using this id. This should be configured for all the RS in the source cluster configuration file for all the RS."]}),`
`]}),`
`,e.jsxs(t.p,{children:["For example: If source cluster FS client configurations are copied to the destination cluster under directory ",e.jsx(t.code,{children:"/home/user/dc1/"}),", then ",e.jsx(t.code,{children:"hbase.replication.cluster.id"})," should be configured as ",e.jsx(t.code,{children:"dc1"})," and ",e.jsx(t.code,{children:"hbase.replication.conf.dir"})," as ",e.jsx(t.code,{children:"/home/user"}),"."]}),`
`,e.jsx(a,{type:"info",children:e.jsxs(t.p,{children:[e.jsx(t.code,{children:"DefaultSourceFSConfigurationProvider"})," supports only ",e.jsx(t.code,{children:"xml"}),` type files. It loads source cluster FS
client configuration only once, so if source cluster FS client configuration files are updated,
every peer(s) cluster RS must be restarted to reload the configuration.`]})})]})}function u(o={}){const{wrapper:t}=o.components||{};return t?e.jsx(t,{...o,children:e.jsx(i,{...o})}):i(o)}function n(o,t){throw new Error("Expected component `"+o+"` to be defined: you likely forgot to import, pass, or provide it.")}export{s as _markdown,u as default,d as extractedReferences,l as frontmatter,c as structuredData,h as toc};
